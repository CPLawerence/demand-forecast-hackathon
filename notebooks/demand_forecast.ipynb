{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Forecast Model\n",
    "\n",
    "This notebook generates demand forecasts and inventory projections by SKU and planning category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration\n",
    "\n",
    "- Set file paths and parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the directory where this notebook is located\n",
    "base_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "# File paths (relative to repository root)\n",
    "catalog_file = os.path.join(base_path, 'catalog_2025-12-09-1340.csv')\n",
    "inventory_file = os.path.join(base_path, 'on hand inventory_2025-12-09-1341.csv')\n",
    "sales_file = os.path.join(base_path, 'sku sales_2025-12-09-1347.csv')\n",
    "on_order_file = os.path.join(base_path, 'CZ On Order Sample Data.xlsx')\n",
    "output_file = os.path.join(base_path, 'Demand_Forecast_Inventory_Model.xlsx')\n",
    "\n",
    "# Output file paths (save to data folder)\n",
    "data_path = os.path.join(base_path, 'data')\n",
    "os.makedirs(data_path, exist_ok=True)  # Create data folder if it doesn't exist\n",
    "demand_forecast_file = os.path.join(data_path, 'demand_forecast_file.csv')\n",
    "demand_forecast_sku_file = os.path.join(data_path, 'demand_forecast_sku.csv')\n",
    "demand_forecast_pivot_file = os.path.join(data_path, 'demand_forecast_pivot.xlsx')\n",
    "\n",
    "# ROS and Curve data files\n",
    "ros_file = os.path.join(base_path, 'CZ Sample ROS Data.csv')\n",
    "curve_file = os.path.join(base_path, 'CZ Sample Curve data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "Loaded ROS data for 4421 SKUs\n",
      "Loaded Curve data for 10 categories: ['ACCENTS', 'BASKETS', 'BATH', 'BEDDING', 'BLANKETS', 'FURNITURE', 'FURNITURE - MTO', 'PILLOWS', 'RUGS', 'TABLEWARE']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data files...\")\n",
    "\n",
    "# Load catalog\n",
    "catalog = pd.read_csv(catalog_file)\n",
    "catalog = catalog.rename(columns={'SKU': 'SKU'})\n",
    "\n",
    "# Load sales\n",
    "sales = pd.read_csv(sales_file)\n",
    "sales = sales.rename(columns={'COMPONENT_SKU': 'SKU'})\n",
    "sales['ORDER_DATE'] = pd.to_datetime(sales['ORDER_DATE'])\n",
    "sales['ORDER_MONTH'] = pd.to_datetime(sales['ORDER_MONTH'])\n",
    "\n",
    "# Load ROS data (daily rate of sale)\n",
    "ros_data = pd.read_csv(ros_file)\n",
    "ros_data.columns = ros_data.columns.str.strip()\n",
    "ros_data['VARIANT_SKU'] = ros_data['VARIANT_SKU'].str.strip()\n",
    "# Convert ROS to numeric, treating '-' and blanks as 0\n",
    "ros_data['NORMALIZED_ROS'] = pd.to_numeric(ros_data['NORMALIZED_ROS'], errors='coerce').fillna(0)\n",
    "# Create a lookup dictionary for ROS by SKU\n",
    "ros_lookup = dict(zip(ros_data['VARIANT_SKU'], ros_data['NORMALIZED_ROS']))\n",
    "print(f\"Loaded ROS data for {len(ros_lookup)} SKUs\")\n",
    "\n",
    "# Load Curve data (monthly sales curve by category)\n",
    "curve_data = pd.read_excel(curve_file)\n",
    "# Column B is the category (matches CATEGORY field in catalog)\n",
    "curve_data = curve_data.rename(columns={'Gross Item Finance Forecast CURVE': 'CATEGORY'})\n",
    "# Set category as index for easy lookup\n",
    "curve_data = curve_data.set_index('CATEGORY')\n",
    "# Drop any unnamed columns (na=False treats NaN column names as False, not NaN)\n",
    "curve_data = curve_data.loc[:, ~curve_data.columns.str.contains('Unnamed', na=False)]\n",
    "# Convert column names to datetime for easier matching\n",
    "curve_data.columns = pd.to_datetime(curve_data.columns, errors='coerce')\n",
    "print(f\"Loaded Curve data for {len(curve_data)} categories: {curve_data.index.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Time Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the most recent date with actual sales data\n",
    "max_sales_date = sales['ORDER_DATE'].max()\n",
    "print(f\"Most recent date with actual sales data: {max_sales_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Determine current date and forecast horizon\n",
    "current_date = datetime(2025, 12, 1)\n",
    "history_start = datetime(2023, 1, 1)\n",
    "forecast_end = datetime(2026, 12, 31)  # Forecast through end of 2026\n",
    "\n",
    "# Create month range for historical + forecast\n",
    "all_months = pd.date_range(start=history_start, end=forecast_end, freq='MS')\n",
    "historical_months = [m for m in all_months if m <= current_date]\n",
    "forecast_months_list = [m for m in all_months if m > current_date]\n",
    "\n",
    "print(f\"Historical months: {len(historical_months)}, Forecast months: {len(forecast_months_list)}\")\n",
    "\n",
    "# Load current-month daily forecast to measure progress\n",
    "progress_file = os.path.join(base_path, 'data', 'Current Month Daily Forecast.csv')\n",
    "col_forecast = 'Discounted Rev Forecast'  # Column B\n",
    "col_actual = 'Actual Discounted Revenue'  # Column C\n",
    "pct_month_complete = np.nan\n",
    "pct_month_left = np.nan\n",
    "\n",
    "if os.path.exists(progress_file):\n",
    "    progress_df = pd.read_csv(progress_file)\n",
    "    missing_cols = [c for c in (col_forecast, col_actual) if c not in progress_df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: {progress_file} missing columns: {missing_cols}\")\n",
    "    else:\n",
    "        # Helper function to clean currency values (remove $, commas, and whitespace)\n",
    "        def clean_currency(value):\n",
    "            if pd.isna(value) or value == '':\n",
    "                return 0\n",
    "            if isinstance(value, str):\n",
    "                return float(value.replace('$', '').replace(',', '').strip())\n",
    "            return float(value)\n",
    "        \n",
    "        # Convert currency strings to numeric values\n",
    "        actual_series = progress_df[col_actual].apply(clean_currency)\n",
    "        forecast_series = progress_df[col_forecast].apply(clean_currency)\n",
    "\n",
    "        # Find last row with a filled actual value (not NaN and > 0)\n",
    "        last_filled_idx = actual_series[actual_series.notna() & (actual_series > 0)].last_valid_index()\n",
    "\n",
    "        if last_filled_idx is not None:\n",
    "            actuals_to_date = actual_series.loc[:last_filled_idx].sum()\n",
    "            remaining_forecast = forecast_series.loc[last_filled_idx + 1:].sum()\n",
    "        else:\n",
    "            # No actuals yet; everything is remaining\n",
    "            actuals_to_date = 0\n",
    "            remaining_forecast = forecast_series.sum()\n",
    "\n",
    "        denom = actuals_to_date + remaining_forecast\n",
    "        pct_month_complete = actuals_to_date / denom if denom else np.nan\n",
    "        pct_month_left = 1 - pct_month_complete if denom else np.nan\n",
    "\n",
    "        print(f\"Current-month progress loaded from: {progress_file}\")\n",
    "        print(f\"  Actuals to date: ${actuals_to_date:,.2f}\")\n",
    "        print(f\"  Remaining forecast: ${remaining_forecast:,.2f}\")\n",
    "        print(f\"  Total: ${denom:,.2f}\")\n",
    "        print(f\"  % month complete: {pct_month_complete:.2%}\" if not np.isnan(pct_month_complete) else \"  % month complete: NaN\")\n",
    "        print(f\"  % month left: {pct_month_left:.2%}\" if not np.isnan(pct_month_left) else \"  % month left: NaN\")\n",
    "else:\n",
    "    print(f\"Warning: {progress_file} not found; pct_month_complete remains NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique SKUs: 6109\n"
     ]
    }
   ],
   "source": [
    "# Aggregate sales by SKU and month\n",
    "sales_agg = sales.groupby(['SKU', 'ORDER_MONTH'])['UNITS_SOLD'].sum().reset_index()\n",
    "sales_agg = sales_agg.rename(columns={'ORDER_MONTH': 'MONTH'})\n",
    "\n",
    "\n",
    "# Get all unique SKUs from catalog\n",
    "all_skus = catalog['SKU'].unique()\n",
    "print(f\"Total unique SKUs: {len(all_skus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Forecast Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forecast(sku, category, forecast_month, ros_lookup, curve_data, daily_ros=None, annual_units=None):\n",
    "    \"\"\"\n",
    "    Calculate forecast for a SKU using:\n",
    "    1. ROS (Rate of Sale) data - daily ROS x 365 days\n",
    "    2. Monthly sales curve applied by category to annual units\n",
    "\n",
    "    Args:\n",
    "        sku: The SKU identifier\n",
    "        category: The category for curve lookup (from catalog CATEGORY field)\n",
    "        forecast_month: The month to forecast (datetime)\n",
    "        ros_lookup: Dictionary of SKU -> daily ROS\n",
    "        curve_data: DataFrame with monthly curve percentages by category\n",
    "        daily_ros: Optional pre-calculated daily ROS (if None, will calculate from ros_lookup)\n",
    "        annual_units: Optional pre-calculated annual units (if None, will calculate from daily_ros)\n",
    "\n",
    "    Returns:\n",
    "        Monthly forecasted units\n",
    "    \"\"\"\n",
    "    # Get daily ROS for this SKU (use provided value or calculate)\n",
    "    if daily_ros is None:\n",
    "        daily_ros = ros_lookup.get(sku, 0)\n",
    "\n",
    "    # Calculate annual units from daily ROS (daily × 365 days) (use provided value or calculate)\n",
    "    if annual_units is None:\n",
    "        annual_units = daily_ros * 365\n",
    "\n",
    "    # Get the monthly curve percentage for this month and category\n",
    "    # The curve represents the proportion of annual sales for each month\n",
    "    month_curve_pct = 1.0 / 12.0  # Default to average (1/12) if no curve found\n",
    "\n",
    "    # Use category directly from catalog (no mapping needed)\n",
    "    if category and category in curve_data.index:\n",
    "        # Find the matching month in the curve data (match by month number)\n",
    "        forecast_month_num = forecast_month.month\n",
    "        for curve_col in curve_data.columns:\n",
    "            if pd.notna(curve_col) and curve_col.month == forecast_month_num:\n",
    "                # Get the curve percentage for this month\n",
    "                month_curve_pct = curve_data.loc[category, curve_col]\n",
    "                break\n",
    "\n",
    "    # Calculate monthly forecast: annual units × monthly curve percentage\n",
    "    unit_demand = annual_units * month_curve_pct\n",
    "\n",
    "    return unit_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Forecast Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating forecasts for all SKU-month combinations...\n",
      "\n",
      "Forecast output created:\n",
      "  Total rows: 293,232\n",
      "  Unique SKUs: 6,109\n",
      "  Date range: 2023-01-01 00:00:00 to 2026-12-01 00:00:00\n",
      "\n",
      "Sample output:\n",
      "                         SKU      MONTH  daily_ros  annual_units  unit_demand  \\\n",
      "0  000004556-004-FL-S-002-B1 2023-01-01        0.0           0.0          0.0   \n",
      "1  000004556-004-FL-S-002-B1 2023-02-01        0.0           0.0          0.0   \n",
      "2  000004556-004-FL-S-002-B1 2023-03-01        0.0           0.0          0.0   \n",
      "3  000004556-004-FL-S-002-B1 2023-04-01        0.0           0.0          0.0   \n",
      "4  000004556-004-FL-S-002-B1 2023-05-01        0.0           0.0          0.0   \n",
      "5  000004556-004-FL-S-002-B1 2023-06-01        0.0           0.0          0.0   \n",
      "6  000004556-004-FL-S-002-B1 2023-07-01        0.0           0.0          0.0   \n",
      "7  000004556-004-FL-S-002-B1 2023-08-01        0.0           0.0          0.0   \n",
      "8  000004556-004-FL-S-002-B1 2023-09-01        0.0           0.0          0.0   \n",
      "9  000004556-004-FL-S-002-B1 2023-10-01        0.0           0.0          0.0   \n",
      "\n",
      "   units_sold  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "5         0.0  \n",
      "6         0.0  \n",
      "7         0.0  \n",
      "8         0.0  \n",
      "9         0.0  \n"
     ]
    }
   ],
   "source": [
    "## Generate Forecast \n",
    "\n",
    "# Create a dataframe with all SKU and month combinations\n",
    "forecast_output = pd.DataFrame({\n",
    "    'SKU': np.repeat(all_skus, len(all_months)),\n",
    "    'MONTH': np.tile(all_months, len(all_skus))\n",
    "})\n",
    "\n",
    "# Add daily ROS\n",
    "forecast_output['daily_ros'] = forecast_output['SKU'].map(ros_lookup).fillna(0)\n",
    "\n",
    "# Calculate annual units (daily ROS × 365)\n",
    "forecast_output['annual_units'] = forecast_output['daily_ros'] * 365\n",
    "\n",
    "# Get category for each SKU from catalog\n",
    "sku_category_map = dict(zip(catalog['SKU'], catalog['CATEGORY']))\n",
    "forecast_output['CATEGORY'] = forecast_output['SKU'].map(sku_category_map)\n",
    "\n",
    "# Calculate unit_demand using the forecast function (pass pre-calculated values to avoid duplication)\n",
    "print(\"Calculating forecasts for all SKU-month combinations...\")\n",
    "forecast_output['unit_demand'] = forecast_output.apply(\n",
    "    lambda row: calculate_forecast(\n",
    "        row['SKU'], \n",
    "        row['CATEGORY'], \n",
    "        row['MONTH'], \n",
    "        ros_lookup, \n",
    "        curve_data,\n",
    "        daily_ros=row['daily_ros'],  # Pass pre-calculated value\n",
    "        annual_units=row['annual_units']  # Pass pre-calculated value\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Merge units_sold from sales_agg (will be null/zero for future months)\n",
    "forecast_output = forecast_output.merge(\n",
    "    sales_agg[['SKU', 'MONTH', 'UNITS_SOLD']], \n",
    "    on=['SKU', 'MONTH'], \n",
    "    how='left'\n",
    ")\n",
    "# Set units_sold: use UNITS_SOLD for historical months, NaN for future months\n",
    "forecast_output['units_sold'] = forecast_output.apply(\n",
    "    lambda row: row['UNITS_SOLD'] if row['MONTH'] <= current_date else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "# Fill NaN for historical months that don't have sales data with 0\n",
    "forecast_output.loc[forecast_output['MONTH'] <= current_date, 'units_sold'] = forecast_output.loc[forecast_output['MONTH'] <= current_date, 'units_sold'].fillna(0)\n",
    "\n",
    "# Select and reorder final columns\n",
    "forecast_output = forecast_output[['SKU', 'MONTH', 'daily_ros', 'annual_units', 'unit_demand', 'units_sold']]\n",
    "\n",
    "# Sort by SKU and MONTH\n",
    "forecast_output = forecast_output.sort_values(['SKU', 'MONTH']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nForecast output created:\")\n",
    "print(f\"  Total rows: {len(forecast_output):,}\")\n",
    "print(f\"  Unique SKUs: {forecast_output['SKU'].nunique():,}\")\n",
    "print(f\"  Date range: {forecast_output['MONTH'].min()} to {forecast_output['MONTH'].max()}\")\n",
    "print(f\"\\nSample output:\")\n",
    "print(forecast_output.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Output Files\n",
    "- for planner review if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created demand_forecast_file: /Users/callie/shared/demand-forecast-hackathon/data/demand_forecast_file.csv\n",
      "  Rows: 293,232\n",
      "\n",
      "✓ Created demand_forecast_sku: /Users/callie/shared/demand-forecast-hackathon/data/demand_forecast_sku.csv\n",
      "  Unique SKUs: 6,109\n",
      "\n",
      "✓ Created demand_forecast_pivot: /Users/callie/shared/demand-forecast-hackathon/data/demand_forecast_pivot.xlsx\n",
      "  Rows: 6,109\n",
      "  Columns: 93 (including 84 month columns)\n",
      "\n",
      "============================================================\n",
      "All output files created successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. demand_forecast_file: SKU, MONTH, UNIT DEMAND, UNIT SALES\n",
    "demand_forecast_output = forecast_output[['SKU', 'MONTH', 'unit_demand', 'units_sold']].copy()\n",
    "demand_forecast_output = demand_forecast_output.rename(columns={\n",
    "    'SKU': 'SKU',\n",
    "    'MONTH': 'MONTH',\n",
    "    'unit_demand': 'UNIT DEMAND',\n",
    "    'units_sold': 'UNIT SALES'\n",
    "})\n",
    "demand_forecast_output.to_csv(demand_forecast_file, index=False)\n",
    "print(f\"✓ Created demand_forecast_file: {demand_forecast_file}\")\n",
    "print(f\"  Rows: {len(demand_forecast_output):,}\")\n",
    "\n",
    "# 2. demand_forecast_sku: SKU, DAILY ROS, ANNUAL UNITS (one row per SKU)\n",
    "demand_forecast_sku = forecast_output[['SKU', 'daily_ros', 'annual_units']].drop_duplicates(subset=['SKU']).copy()\n",
    "demand_forecast_sku = demand_forecast_sku.rename(columns={\n",
    "    'SKU': 'SKU',\n",
    "    'daily_ros': 'DAILY ROS',\n",
    "    'annual_units': 'ANNUAL UNITS'\n",
    "})\n",
    "demand_forecast_sku = demand_forecast_sku.sort_values('SKU').reset_index(drop=True)\n",
    "demand_forecast_sku.to_csv(demand_forecast_sku_file, index=False)\n",
    "print(f\"\\n✓ Created demand_forecast_sku: {demand_forecast_sku_file}\")\n",
    "print(f\"  Unique SKUs: {len(demand_forecast_sku):,}\")\n",
    "\n",
    "# 3. Excel file with catalog fields + pivoted UNIT SALES and UNIT DEMAND by month\n",
    "# First, get catalog fields for each SKU (check which fields exist)\n",
    "required_catalog_fields = ['SKU', 'SKU_DESCRIPTION', 'CATEGORY', 'SUB_CATEGORY', 'COLLECTION', \n",
    "                           'PLANNING_STATUS', 'LAUNCH_YEAR_SEASON', 'VENDOR_COST_USD', 'FULL_PRICE_RETAIL']\n",
    "available_fields = [field for field in required_catalog_fields if field in catalog.columns]\n",
    "missing_fields = [field for field in required_catalog_fields if field not in catalog.columns]\n",
    "\n",
    "if missing_fields:\n",
    "    print(f\"Warning: Missing catalog fields: {missing_fields}\")\n",
    "    print(f\"Available catalog columns: {list(catalog.columns)}\")\n",
    "\n",
    "catalog_fields = catalog[available_fields].copy()\n",
    "\n",
    "# Create pivot tables for UNIT SALES and UNIT DEMAND\n",
    "unit_sales_pivot = forecast_output.pivot_table(\n",
    "    index='SKU', \n",
    "    columns='MONTH', \n",
    "    values='units_sold', \n",
    "    fill_value=0\n",
    ")\n",
    "unit_sales_pivot.columns = [f\"UNIT SALES {col.strftime('%Y-%m')}\" for col in unit_sales_pivot.columns]\n",
    "\n",
    "unit_demand_pivot = forecast_output.pivot_table(\n",
    "    index='SKU', \n",
    "    columns='MONTH', \n",
    "    values='unit_demand', \n",
    "    fill_value=0\n",
    ")\n",
    "unit_demand_pivot.columns = [f\"UNIT DEMAND {col.strftime('%Y-%m')}\" for col in unit_demand_pivot.columns]\n",
    "\n",
    "# Merge catalog fields with pivot tables\n",
    "demand_forecast_pivot = catalog_fields.merge(unit_sales_pivot, on='SKU', how='left')\n",
    "demand_forecast_pivot = demand_forecast_pivot.merge(unit_demand_pivot, on='SKU', how='left')\n",
    "\n",
    "# Fill NaN values with 0 for the pivot columns\n",
    "pivot_cols = [col for col in demand_forecast_pivot.columns if 'UNIT SALES' in col or 'UNIT DEMAND' in col]\n",
    "demand_forecast_pivot[pivot_cols] = demand_forecast_pivot[pivot_cols].fillna(0)\n",
    "\n",
    "# Reorder columns: catalog fields first, then UNIT SALES (chronological), then UNIT DEMAND (chronological)\n",
    "catalog_cols = [col for col in demand_forecast_pivot.columns if col not in pivot_cols]\n",
    "unit_sales_cols = sorted([col for col in pivot_cols if 'UNIT SALES' in col])\n",
    "unit_demand_cols = sorted([col for col in pivot_cols if 'UNIT DEMAND' in col])\n",
    "demand_forecast_pivot = demand_forecast_pivot[catalog_cols + unit_sales_cols + unit_demand_cols]\n",
    "\n",
    "# Sort by SKU\n",
    "demand_forecast_pivot = demand_forecast_pivot.sort_values('SKU').reset_index(drop=True)\n",
    "\n",
    "# Export to Excel\n",
    "with pd.ExcelWriter(demand_forecast_pivot_file, engine='xlsxwriter') as writer:\n",
    "    demand_forecast_pivot.to_excel(writer, sheet_name='Demand Forecast', index=False)\n",
    "    \n",
    "    # Get the workbook and worksheet objects\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Demand Forecast']\n",
    "    \n",
    "    # Format header row\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'bg_color': '#4472C4',\n",
    "        'font_color': 'white',\n",
    "        'border': 1,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter'\n",
    "    })\n",
    "    \n",
    "    # Apply header format\n",
    "    for col_num, value in enumerate(demand_forecast_pivot.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "    \n",
    "    # Set column widths\n",
    "    worksheet.set_column(0, 0, 25)  # SKU\n",
    "    worksheet.set_column(1, 1, 40)  # SKU_DESCRIPTION\n",
    "    worksheet.set_column(2, 8, 15)  # Catalog fields\n",
    "    worksheet.set_column(9, len(demand_forecast_pivot.columns) - 1, 12)  # Month columns\n",
    "\n",
    "print(f\"\\n✓ Created demand_forecast_pivot: {demand_forecast_pivot_file}\")\n",
    "print(f\"  Rows: {len(demand_forecast_pivot):,}\")\n",
    "print(f\"  Columns: {len(demand_forecast_pivot.columns):,} (including {len(pivot_cols)} month columns)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All output files created successfully!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Forecast Model\n",
    "\n",
    "This notebook generates demand forecasts and inventory projections by SKU and planning category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T16:37:24.797621Z",
     "iopub.status.busy": "2025-12-12T16:37:24.796622Z",
     "iopub.status.idle": "2025-12-12T16:37:25.487834Z",
     "shell.execute_reply": "2025-12-12T16:37:25.486828Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration\n",
    "\n",
    "- Set file paths and parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T16:37:25.489834Z",
     "iopub.status.busy": "2025-12-12T16:37:25.488852Z",
     "iopub.status.idle": "2025-12-12T16:37:25.495882Z",
     "shell.execute_reply": "2025-12-12T16:37:25.495374Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the directory where this notebook is located\n",
    "base_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "# Repository root is one level up from notebooks folder\n",
    "repo_root = os.path.join(base_path, '..')\n",
    "\n",
    "# File paths (relative to repository root)\n",
    "catalog_file = os.path.join(repo_root, 'catalog_2025-12-09-1340.csv')\n",
    "inventory_file = os.path.join(repo_root, 'on hand inventory_2025-12-09-1341.csv')\n",
    "sales_file = os.path.join(repo_root, 'sku sales_2025-12-09-1347.csv')\n",
    "on_order_file = os.path.join(repo_root, 'CZ On Order Sample Data.xlsx')\n",
    "output_file = os.path.join(repo_root, 'Demand_Forecast_Inventory_Model.xlsx')\n",
    "\n",
    "# Output file paths (save to data folder)\n",
    "data_path = os.path.join(repo_root, 'data')\n",
    "os.makedirs(data_path, exist_ok=True)  # Create data folder if it doesn't exist\n",
    "demand_forecast_file = os.path.join(data_path, 'demand_forecast_file.csv')\n",
    "demand_forecast_sku_file = os.path.join(data_path, 'demand_forecast_sku.csv')\n",
    "demand_forecast_pivot_file = os.path.join(data_path, 'demand_forecast_pivot.xlsx')\n",
    "\n",
    "# ROS and Curve data files\n",
    "ros_file = os.path.join(repo_root, 'CZ Sample ROS Data.csv')\n",
    "curve_file = os.path.join(repo_root, 'CZ Sample Curve data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T16:37:25.500418Z",
     "iopub.status.busy": "2025-12-12T16:37:25.500418Z",
     "iopub.status.idle": "2025-12-12T16:37:26.035588Z",
     "shell.execute_reply": "2025-12-12T16:37:26.035588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ROS data for 4421 SKUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Curve data for 10 categories: ['ACCENTS', 'BASKETS', 'BATH', 'BEDDING', 'BLANKETS', 'FURNITURE', 'FURNITURE - MTO', 'PILLOWS', 'RUGS', 'TABLEWARE']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data files...\")\n",
    "\n",
    "# Load catalog\n",
    "catalog = pd.read_csv(catalog_file)\n",
    "catalog = catalog.rename(columns={'SKU': 'SKU'})\n",
    "\n",
    "# Load sales\n",
    "sales = pd.read_csv(sales_file)\n",
    "sales = sales.rename(columns={'COMPONENT_SKU': 'SKU'})\n",
    "sales['ORDER_DATE'] = pd.to_datetime(sales['ORDER_DATE'])\n",
    "sales['ORDER_MONTH'] = pd.to_datetime(sales['ORDER_MONTH'])\n",
    "\n",
    "# Load ROS data (daily rate of sale)\n",
    "ros_data = pd.read_csv(ros_file)\n",
    "ros_data.columns = ros_data.columns.str.strip()\n",
    "ros_data['VARIANT_SKU'] = ros_data['VARIANT_SKU'].str.strip()\n",
    "# Convert ROS to numeric, treating '-' and blanks as 0\n",
    "ros_data['NORMALIZED_ROS'] = pd.to_numeric(ros_data['NORMALIZED_ROS'], errors='coerce').fillna(0)\n",
    "# Create a lookup dictionary for ROS by SKU\n",
    "ros_lookup = dict(zip(ros_data['VARIANT_SKU'], ros_data['NORMALIZED_ROS']))\n",
    "print(f\"Loaded ROS data for {len(ros_lookup)} SKUs\")\n",
    "\n",
    "# Load Curve data (monthly sales curve by category)\n",
    "curve_data = pd.read_excel(curve_file)\n",
    "# Column B is the category (matches CATEGORY field in catalog)\n",
    "curve_data = curve_data.rename(columns={'Gross Item Finance Forecast CURVE': 'CATEGORY'})\n",
    "# Set category as index for easy lookup\n",
    "curve_data = curve_data.set_index('CATEGORY')\n",
    "# Drop any unnamed columns (na=False treats NaN column names as False, not NaN)\n",
    "curve_data = curve_data.loc[:, ~curve_data.columns.str.contains('Unnamed', na=False)]\n",
    "# Convert column names to datetime for easier matching\n",
    "curve_data.columns = pd.to_datetime(curve_data.columns, errors='coerce')\n",
    "print(f\"Loaded Curve data for {len(curve_data)} categories: {curve_data.index.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Time Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T16:37:26.037607Z",
     "iopub.status.busy": "2025-12-12T16:37:26.037607Z",
     "iopub.status.idle": "2025-12-12T16:37:26.047906Z",
     "shell.execute_reply": "2025-12-12T16:37:26.047906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent date with actual sales data: 2025-12-09\n",
      "Historical months: 36, Forecast months: 12\n",
      "Current-month progress loaded from: C:\\Users\\JaeheeKim\\demand-forecast-hackathon-1\\notebooks\\..\\data\\Current Month Daily Forecast.csv\n",
      "  Actuals to date: $1,008,933.00\n",
      "  Remaining forecast: $1,360,000.00\n",
      "  Total: $2,368,933.00\n",
      "  % month complete: 42.59%\n",
      "  % month left: 57.41%\n"
     ]
    }
   ],
   "source": [
    "# Determine the most recent date with actual sales data\n",
    "max_sales_date = sales['ORDER_DATE'].max()\n",
    "print(f\"Most recent date with actual sales data: {max_sales_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Determine current date and forecast horizon\n",
    "current_date = datetime(2025, 12, 1)\n",
    "history_start = datetime(2023, 1, 1)\n",
    "forecast_end = datetime(2026, 12, 31)  # Forecast through end of 2026\n",
    "\n",
    "# Create month range for historical + forecast\n",
    "all_months = pd.date_range(start=history_start, end=forecast_end, freq='MS')\n",
    "historical_months = [m for m in all_months if m <= current_date]\n",
    "forecast_months_list = [m for m in all_months if m > current_date]\n",
    "\n",
    "print(f\"Historical months: {len(historical_months)}, Forecast months: {len(forecast_months_list)}\")\n",
    "\n",
    "# Load current-month daily forecast to measure progress\n",
    "progress_file = os.path.join(repo_root, 'data', 'Current Month Daily Forecast.csv')\n",
    "col_forecast = 'Discounted Rev Forecast'  # Column B\n",
    "col_actual = 'Actual Discounted Revenue'  # Column C\n",
    "pct_month_complete = np.nan\n",
    "pct_month_left = np.nan\n",
    "\n",
    "if os.path.exists(progress_file):\n",
    "    progress_df = pd.read_csv(progress_file)\n",
    "    missing_cols = [c for c in (col_forecast, col_actual) if c not in progress_df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: {progress_file} missing columns: {missing_cols}\")\n",
    "    else:\n",
    "        # Helper function to clean currency values (remove $, commas, and whitespace)\n",
    "        def clean_currency(value):\n",
    "            if pd.isna(value) or value == '':\n",
    "                return 0\n",
    "            if isinstance(value, str):\n",
    "                return float(value.replace('$', '').replace(',', '').strip())\n",
    "            return float(value)\n",
    "        \n",
    "        # Convert currency strings to numeric values\n",
    "        actual_series = progress_df[col_actual].apply(clean_currency)\n",
    "        forecast_series = progress_df[col_forecast].apply(clean_currency)\n",
    "\n",
    "        # Find last row with a filled actual value (not NaN and > 0)\n",
    "        last_filled_idx = actual_series[actual_series.notna() & (actual_series > 0)].last_valid_index()\n",
    "\n",
    "        if last_filled_idx is not None:\n",
    "            actuals_to_date = actual_series.loc[:last_filled_idx].sum()\n",
    "            remaining_forecast = forecast_series.loc[last_filled_idx + 1:].sum()\n",
    "        else:\n",
    "            # No actuals yet; everything is remaining\n",
    "            actuals_to_date = 0\n",
    "            remaining_forecast = forecast_series.sum()\n",
    "\n",
    "        denom = actuals_to_date + remaining_forecast\n",
    "        pct_month_complete = actuals_to_date / denom if denom else np.nan\n",
    "        pct_month_left = 1 - pct_month_complete if denom else np.nan\n",
    "\n",
    "        print(f\"Current-month progress loaded from: {progress_file}\")\n",
    "        print(f\"  Actuals to date: ${actuals_to_date:,.2f}\")\n",
    "        print(f\"  Remaining forecast: ${remaining_forecast:,.2f}\")\n",
    "        print(f\"  Total: ${denom:,.2f}\")\n",
    "        print(f\"  % month complete: {pct_month_complete:.2%}\" if not np.isnan(pct_month_complete) else \"  % month complete: NaN\")\n",
    "        print(f\"  % month left: {pct_month_left:.2%}\" if not np.isnan(pct_month_left) else \"  % month left: NaN\")\n",
    "else:\n",
    "    print(f\"Warning: {progress_file} not found; pct_month_complete remains NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T16:37:26.050917Z",
     "iopub.status.busy": "2025-12-12T16:37:26.050917Z",
     "iopub.status.idle": "2025-12-12T16:37:26.092408Z",
     "shell.execute_reply": "2025-12-12T16:37:26.092336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique SKUs: 6109\n"
     ]
    }
   ],
   "source": [
    "# Aggregate sales by SKU and month\n",
    "sales_agg = sales.groupby(['SKU', 'ORDER_MONTH'])['UNITS_SOLD'].sum().reset_index()\n",
    "sales_agg = sales_agg.rename(columns={'ORDER_MONTH': 'MONTH'})\n",
    "\n",
    "\n",
    "# Get all unique SKUs from catalog\n",
    "all_skus = catalog['SKU'].unique()\n",
    "print(f\"Total unique SKUs: {len(all_skus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Forecast Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T16:37:26.095624Z",
     "iopub.status.busy": "2025-12-12T16:37:26.094446Z",
     "iopub.status.idle": "2025-12-12T16:37:26.100966Z",
     "shell.execute_reply": "2025-12-12T16:37:26.099947Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_forecast(sku, category, forecast_month, ros_lookup, curve_data, daily_ros=None, annual_units=None):\n",
    "    \"\"\"\n",
    "    Calculate forecast for a SKU using:\n",
    "    1. ROS (Rate of Sale) data - daily ROS x 365 days\n",
    "    2. Monthly sales curve applied by category to annual units\n",
    "\n",
    "    Args:\n",
    "        sku: The SKU identifier\n",
    "        category: The category for curve lookup (from catalog CATEGORY field)\n",
    "        forecast_month: The month to forecast (datetime)\n",
    "        ros_lookup: Dictionary of SKU -> daily ROS\n",
    "        curve_data: DataFrame with monthly curve percentages by category\n",
    "        daily_ros: Optional pre-calculated daily ROS (if None, will calculate from ros_lookup)\n",
    "        annual_units: Optional pre-calculated annual units (if None, will calculate from daily_ros)\n",
    "\n",
    "    Returns:\n",
    "        Monthly forecasted units\n",
    "    \"\"\"\n",
    "    # Get daily ROS for this SKU (use provided value or calculate)\n",
    "    if daily_ros is None:\n",
    "        daily_ros = ros_lookup.get(sku, 0)\n",
    "\n",
    "    # Calculate annual units from daily ROS (daily × 365 days) (use provided value or calculate)\n",
    "    if annual_units is None:\n",
    "        annual_units = daily_ros * 365\n",
    "\n",
    "    # Get the monthly curve percentage for this month and category\n",
    "    # The curve represents the proportion of annual sales for each month\n",
    "    month_curve_pct = 1.0 / 12.0  # Default to average (1/12) if no curve found\n",
    "\n",
    "    # Use category directly from catalog (no mapping needed)\n",
    "    if category and category in curve_data.index:\n",
    "        # Find the matching month in the curve data (match by month number)\n",
    "        forecast_month_num = forecast_month.month\n",
    "        for curve_col in curve_data.columns:\n",
    "            if pd.notna(curve_col) and curve_col.month == forecast_month_num:\n",
    "                # Get the curve percentage for this month\n",
    "                month_curve_pct = curve_data.loc[category, curve_col]\n",
    "                break\n",
    "\n",
    "    # Calculate monthly forecast: annual units × monthly curve percentage\n",
    "    unit_demand = annual_units * month_curve_pct\n",
    "\n",
    "    return unit_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Forecast Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T16:37:26.102104Z",
     "iopub.status.busy": "2025-12-12T16:37:26.102104Z",
     "iopub.status.idle": "2025-12-12T16:37:34.858305Z",
     "shell.execute_reply": "2025-12-12T16:37:34.858305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating forecasts for all SKU-month combinations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecast output created:\n",
      "  Total rows: 293,232\n",
      "  Unique SKUs: 6,109\n",
      "  Date range: 2023-01-01 00:00:00 to 2026-12-01 00:00:00\n",
      "\n",
      "Sample output:\n",
      "                         SKU      MONTH  daily_ros  annual_units  unit_demand  \\\n",
      "0  000004556-004-FL-S-002-B1 2023-01-01        0.0           0.0          0.0   \n",
      "1  000004556-004-FL-S-002-B1 2023-02-01        0.0           0.0          0.0   \n",
      "2  000004556-004-FL-S-002-B1 2023-03-01        0.0           0.0          0.0   \n",
      "3  000004556-004-FL-S-002-B1 2023-04-01        0.0           0.0          0.0   \n",
      "4  000004556-004-FL-S-002-B1 2023-05-01        0.0           0.0          0.0   \n",
      "5  000004556-004-FL-S-002-B1 2023-06-01        0.0           0.0          0.0   \n",
      "6  000004556-004-FL-S-002-B1 2023-07-01        0.0           0.0          0.0   \n",
      "7  000004556-004-FL-S-002-B1 2023-08-01        0.0           0.0          0.0   \n",
      "8  000004556-004-FL-S-002-B1 2023-09-01        0.0           0.0          0.0   \n",
      "9  000004556-004-FL-S-002-B1 2023-10-01        0.0           0.0          0.0   \n",
      "\n",
      "   units_sold  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "5         0.0  \n",
      "6         0.0  \n",
      "7         0.0  \n",
      "8         0.0  \n",
      "9         0.0  \n"
     ]
    }
   ],
   "source": [
    "## Generate Forecast \n",
    "\n",
    "# Create a dataframe with all SKU and month combinations\n",
    "forecast_output = pd.DataFrame({\n",
    "    'SKU': np.repeat(all_skus, len(all_months)),\n",
    "    'MONTH': np.tile(all_months, len(all_skus))\n",
    "})\n",
    "\n",
    "# Add daily ROS\n",
    "forecast_output['daily_ros'] = forecast_output['SKU'].map(ros_lookup).fillna(0)\n",
    "\n",
    "# Calculate annual units (daily ROS × 365)\n",
    "forecast_output['annual_units'] = forecast_output['daily_ros'] * 365\n",
    "\n",
    "# Get category for each SKU from catalog\n",
    "sku_category_map = dict(zip(catalog['SKU'], catalog['CATEGORY']))\n",
    "forecast_output['CATEGORY'] = forecast_output['SKU'].map(sku_category_map)\n",
    "\n",
    "# Calculate unit_demand using the forecast function (pass pre-calculated values to avoid duplication)\n",
    "print(\"Calculating forecasts for all SKU-month combinations...\")\n",
    "forecast_output['unit_demand'] = forecast_output.apply(\n",
    "    lambda row: calculate_forecast(\n",
    "        row['SKU'], \n",
    "        row['CATEGORY'], \n",
    "        row['MONTH'], \n",
    "        ros_lookup, \n",
    "        curve_data,\n",
    "        daily_ros=row['daily_ros'],  # Pass pre-calculated value\n",
    "        annual_units=row['annual_units']  # Pass pre-calculated value\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Merge units_sold from sales_agg (will be null/zero for future months)\n",
    "forecast_output = forecast_output.merge(\n",
    "    sales_agg[['SKU', 'MONTH', 'UNITS_SOLD']], \n",
    "    on=['SKU', 'MONTH'], \n",
    "    how='left'\n",
    ")\n",
    "# Set units_sold: use UNITS_SOLD for historical months, NaN for future months\n",
    "forecast_output['units_sold'] = forecast_output.apply(\n",
    "    lambda row: row['UNITS_SOLD'] if row['MONTH'] <= current_date else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "# Fill NaN for historical months that don't have sales data with 0\n",
    "forecast_output.loc[forecast_output['MONTH'] <= current_date, 'units_sold'] = forecast_output.loc[forecast_output['MONTH'] <= current_date, 'units_sold'].fillna(0)\n",
    "\n",
    "# Select and reorder final columns\n",
    "forecast_output = forecast_output[['SKU', 'MONTH', 'daily_ros', 'annual_units', 'unit_demand', 'units_sold']]\n",
    "\n",
    "# Sort by SKU and MONTH\n",
    "forecast_output = forecast_output.sort_values(['SKU', 'MONTH']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nForecast output created:\")\n",
    "print(f\"  Total rows: {len(forecast_output):,}\")\n",
    "print(f\"  Unique SKUs: {forecast_output['SKU'].nunique():,}\")\n",
    "print(f\"  Date range: {forecast_output['MONTH'].min()} to {forecast_output['MONTH'].max()}\")\n",
    "print(f\"\\nSample output:\")\n",
    "print(forecast_output.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Output Files\n",
    "- for planner review if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T16:37:34.861513Z",
     "iopub.status.busy": "2025-12-12T16:37:34.861513Z",
     "iopub.status.idle": "2025-12-12T16:37:55.056881Z",
     "shell.execute_reply": "2025-12-12T16:37:55.055924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created demand_forecast_file: C:\\Users\\JaeheeKim\\demand-forecast-hackathon-1\\notebooks\\..\\data\\demand_forecast_file.csv\n",
      "  Rows: 293,232\n",
      "\n",
      "✓ Created demand_forecast_sku: C:\\Users\\JaeheeKim\\demand-forecast-hackathon-1\\notebooks\\..\\data\\demand_forecast_sku.csv\n",
      "  Unique SKUs: 6,109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Created demand_forecast_pivot: C:\\Users\\JaeheeKim\\demand-forecast-hackathon-1\\notebooks\\..\\data\\demand_forecast_pivot.xlsx\n",
      "  Rows: 12,218 (2 metrics per SKU)\n",
      "  SKUs: 6,109\n",
      "  Metrics: Unit Demand, Unit Sales\n",
      "  Month columns: 48\n",
      "  All numbers rounded to nearest whole number\n",
      "\n",
      "============================================================\n",
      "All output files created successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. demand_forecast_file: SKU, MONTH, UNIT DEMAND, UNIT SALES\n",
    "demand_forecast_output = forecast_output[['SKU', 'MONTH', 'unit_demand', 'units_sold']].copy()\n",
    "demand_forecast_output = demand_forecast_output.rename(columns={\n",
    "    'SKU': 'SKU',\n",
    "    'MONTH': 'MONTH',\n",
    "    'unit_demand': 'UNIT DEMAND',\n",
    "    'units_sold': 'UNIT SALES'\n",
    "})\n",
    "demand_forecast_output.to_csv(demand_forecast_file, index=False)\n",
    "print(f\"✓ Created demand_forecast_file: {demand_forecast_file}\")\n",
    "print(f\"  Rows: {len(demand_forecast_output):,}\")\n",
    "\n",
    "# 2. demand_forecast_sku: SKU, DAILY ROS, ANNUAL UNITS (one row per SKU)\n",
    "demand_forecast_sku = forecast_output[['SKU', 'daily_ros', 'annual_units']].drop_duplicates(subset=['SKU']).copy()\n",
    "demand_forecast_sku = demand_forecast_sku.rename(columns={\n",
    "    'SKU': 'SKU',\n",
    "    'daily_ros': 'DAILY ROS',\n",
    "    'annual_units': 'ANNUAL UNITS'\n",
    "})\n",
    "demand_forecast_sku = demand_forecast_sku.sort_values('SKU').reset_index(drop=True)\n",
    "demand_forecast_sku.to_csv(demand_forecast_sku_file, index=False)\n",
    "print(f\"\\n✓ Created demand_forecast_sku: {demand_forecast_sku_file}\")\n",
    "print(f\"  Unique SKUs: {len(demand_forecast_sku):,}\")\n",
    "\n",
    "# 3. Excel file with SKU, METRIC, catalog fields, and monthly columns\n",
    "# Each SKU will have 2 rows: one for Unit Sales, one for Unit Demand\n",
    "\n",
    "# Get catalog fields for each SKU\n",
    "required_catalog_fields = ['SKU', 'SKU_DESCRIPTION', 'CATEGORY', 'SUB_CATEGORY', 'COLLECTION', \n",
    "                           'PLANNING_STATUS', 'LAUNCH_YEAR_SEASON', 'VENDOR_COST_USD', 'FULL_PRICE_RETAIL']\n",
    "available_fields = [field for field in required_catalog_fields if field in catalog.columns]\n",
    "missing_fields = [field for field in required_catalog_fields if field not in catalog.columns]\n",
    "\n",
    "if missing_fields:\n",
    "    print(f\"Warning: Missing catalog fields: {missing_fields}\")\n",
    "\n",
    "catalog_fields = catalog[available_fields].copy()\n",
    "\n",
    "# Get all unique months from forecast_output\n",
    "all_months_sorted = sorted(forecast_output['MONTH'].unique())\n",
    "month_col_names = [m.strftime('%Y-%m') for m in all_months_sorted]\n",
    "\n",
    "# Create pivot tables for UNIT SALES and UNIT DEMAND\n",
    "unit_sales_pivot = forecast_output.pivot_table(\n",
    "    index='SKU', \n",
    "    columns='MONTH', \n",
    "    values='units_sold', \n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "# Reindex to ensure all months are present\n",
    "unit_sales_pivot = unit_sales_pivot.reindex(columns=all_months_sorted, fill_value=0)\n",
    "unit_sales_pivot = unit_sales_pivot.reset_index()\n",
    "unit_sales_pivot.columns = ['SKU'] + month_col_names\n",
    "\n",
    "unit_demand_pivot = forecast_output.pivot_table(\n",
    "    index='SKU', \n",
    "    columns='MONTH', \n",
    "    values='unit_demand', \n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "# Reindex to ensure all months are present\n",
    "unit_demand_pivot = unit_demand_pivot.reindex(columns=all_months_sorted, fill_value=0)\n",
    "unit_demand_pivot = unit_demand_pivot.reset_index()\n",
    "unit_demand_pivot.columns = ['SKU'] + month_col_names\n",
    "\n",
    "# Round all numeric columns to nearest whole number\n",
    "for col in month_col_names:\n",
    "    unit_sales_pivot[col] = unit_sales_pivot[col].round(0).astype(int)\n",
    "    unit_demand_pivot[col] = unit_demand_pivot[col].round(0).astype(int)\n",
    "\n",
    "# Add METRIC column\n",
    "unit_sales_pivot['METRIC'] = 'Unit Sales'\n",
    "unit_demand_pivot['METRIC'] = 'Unit Demand'\n",
    "\n",
    "# Combine both metrics\n",
    "combined_pivot = pd.concat([unit_sales_pivot, unit_demand_pivot], ignore_index=True)\n",
    "\n",
    "# Merge with catalog fields\n",
    "combined_pivot = combined_pivot.merge(catalog_fields, on='SKU', how='left')\n",
    "\n",
    "# Reorder columns: SKU, METRIC, catalog fields (except SKU), then months\n",
    "catalog_cols_no_sku = [col for col in available_fields if col != 'SKU']\n",
    "final_cols = ['SKU', 'METRIC'] + catalog_cols_no_sku + month_col_names\n",
    "combined_pivot = combined_pivot[final_cols]\n",
    "\n",
    "# Sort by SKU and METRIC (Unit Demand first, then Unit Sales for each SKU)\n",
    "combined_pivot['METRIC_ORDER'] = combined_pivot['METRIC'].map({'Unit Demand': 0, 'Unit Sales': 1})\n",
    "combined_pivot = combined_pivot.sort_values(['SKU', 'METRIC_ORDER']).reset_index(drop=True)\n",
    "combined_pivot = combined_pivot.drop(columns=['METRIC_ORDER'])\n",
    "\n",
    "# Fill NaN values with 0 for numeric columns and empty string for text columns\n",
    "for col in month_col_names:\n",
    "    combined_pivot[col] = combined_pivot[col].fillna(0)\n",
    "\n",
    "# Export to Excel with formatting (with nan_inf_to_errors option)\n",
    "with pd.ExcelWriter(demand_forecast_pivot_file, engine='xlsxwriter', engine_kwargs={'options': {'nan_inf_to_errors': True}}) as writer:\n",
    "    combined_pivot.to_excel(writer, sheet_name='Demand Forecast', index=False)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Demand Forecast']\n",
    "    \n",
    "    # Header format\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'bg_color': '#4472C4',\n",
    "        'font_color': 'white',\n",
    "        'border': 1,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter'\n",
    "    })\n",
    "    \n",
    "    # Number format (whole numbers)\n",
    "    number_format = workbook.add_format({\n",
    "        'num_format': '#,##0',\n",
    "        'border': 1,\n",
    "        'align': 'right'\n",
    "    })\n",
    "    \n",
    "    # Text format\n",
    "    text_format = workbook.add_format({\n",
    "        'border': 1,\n",
    "        'align': 'left'\n",
    "    })\n",
    "    \n",
    "    # Unit Demand row format (light blue background)\n",
    "    demand_format = workbook.add_format({\n",
    "        'bg_color': '#D9E1F2',\n",
    "        'border': 1,\n",
    "        'align': 'left'\n",
    "    })\n",
    "    \n",
    "    demand_number_format = workbook.add_format({\n",
    "        'bg_color': '#D9E1F2',\n",
    "        'num_format': '#,##0',\n",
    "        'border': 1,\n",
    "        'align': 'right'\n",
    "    })\n",
    "    \n",
    "    # Apply header format\n",
    "    for col_num, value in enumerate(combined_pivot.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "    \n",
    "    # Apply data formatting\n",
    "    for row_num in range(1, len(combined_pivot) + 1):\n",
    "        is_demand_row = combined_pivot.iloc[row_num - 1]['METRIC'] == 'Unit Demand'\n",
    "        \n",
    "        for col_num, col_name in enumerate(combined_pivot.columns):\n",
    "            value = combined_pivot.iloc[row_num - 1, col_num]\n",
    "            \n",
    "            # Handle NaN values\n",
    "            if pd.isna(value):\n",
    "                value = 0 if col_name in month_col_names else ''\n",
    "            \n",
    "            # Check if it's a month column (numeric data)\n",
    "            is_month_col = col_name in month_col_names\n",
    "            \n",
    "            if is_demand_row:\n",
    "                if is_month_col:\n",
    "                    worksheet.write(row_num, col_num, value, demand_number_format)\n",
    "                else:\n",
    "                    worksheet.write(row_num, col_num, value, demand_format)\n",
    "            else:\n",
    "                if is_month_col:\n",
    "                    worksheet.write(row_num, col_num, value, number_format)\n",
    "                else:\n",
    "                    worksheet.write(row_num, col_num, value, text_format)\n",
    "    \n",
    "    # Set column widths\n",
    "    worksheet.set_column(0, 0, 25)  # SKU\n",
    "    worksheet.set_column(1, 1, 12)  # METRIC\n",
    "    worksheet.set_column(2, 2, 40)  # SKU_DESCRIPTION\n",
    "    worksheet.set_column(3, len(catalog_cols_no_sku) + 1, 15)  # Catalog fields\n",
    "    worksheet.set_column(len(catalog_cols_no_sku) + 2, len(combined_pivot.columns) - 1, 10)  # Month columns\n",
    "    \n",
    "    # Freeze first row and first two columns\n",
    "    worksheet.freeze_panes(1, 2)\n",
    "\n",
    "print(f\"\\n✓ Created demand_forecast_pivot: {demand_forecast_pivot_file}\")\n",
    "print(f\"  Rows: {len(combined_pivot):,} (2 metrics per SKU)\")\n",
    "print(f\"  SKUs: {combined_pivot['SKU'].nunique():,}\")\n",
    "print(f\"  Metrics: Unit Demand, Unit Sales\")\n",
    "print(f\"  Month columns: {len(month_col_names)}\")\n",
    "print(f\"  All numbers rounded to nearest whole number\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All output files created successfully!\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
